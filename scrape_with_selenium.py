#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ Selenium çš„ Minecraft Wiki ç‰ˆæœ¬å†å²çˆ¬è™«
ç»•è¿‡åçˆ¬è™«é™åˆ¶
"""

import re
import json

from typing import List, Dict, Optional
from dataclasses import dataclass, asdict
import time

try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False


@dataclass
class VersionRecord:
    """ç‰ˆæœ¬è®°å½•æ•°æ®ç±»"""
    version: str
    date: str
    time: str
    editor: str
    file_size: str
    change_bytes: str
    description: str
    wiki_url: str


class SeleniumScraper:
    """ä½¿ç”¨ Selenium çš„çˆ¬è™«"""
    
    def __init__(self):
        self.base_url = "https://minecraft.wiki"
        self.history_url = "https://minecraft.wiki/w/Java_Edition_protocol/Entity_metadata?action=history&limit=500&offset="
        self.driver = None
    
    def setup_driver(self):
        """è®¾ç½® Chrome é©±åŠ¨"""
        if not SELENIUM_AVAILABLE:
            print("âŒ Selenium æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install selenium")
            print("âŒ è¿˜éœ€è¦ä¸‹è½½ ChromeDriver: https://chromedriver.chromium.org/")
            return False
        
        try:
            chrome_options = Options()
            chrome_options.add_argument('--headless')  # æ— ç•Œé¢æ¨¡å¼
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            self.driver = webdriver.Chrome(options=chrome_options)
            return True
        except Exception as e:
            print(f"âŒ æ— æ³•å¯åŠ¨ Chrome é©±åŠ¨: {e}")
            return False
    
    def extract_version_from_text(self, text: str) -> Optional[str]:
        """ä»æ–‡æœ¬ä¸­æå–ç‰ˆæœ¬å·"""
        if not text:
            return None
        
        patterns = [
            r'update to (1\.\d+(?:\.\d+)?)',  # "update to 1.21.4"
            r'Updated? to (1\.\d+(?:\.\d+)?)', # "Updated to 1.21"
            r'version (1\.\d+(?:\.\d+)?)',    # "version 1.21"
            r'changes for (1\.\d+(?:\.\d+)?)', # "changes for 1.21"
            r'\b(1\.\d+\.\d+)\b',            # "1.21.8" (ä¸‰ä½ç‰ˆæœ¬å·ä¼˜å…ˆ)
            r'\b(1\.\d+)\b',                 # "1.21" (ä¸¤ä½ç‰ˆæœ¬å·)
            r'\((\d+\.\d+(?:\.\d+)?)\)',      # "(1.21.8)"
            r'(\d+\.\d+\+)',                 # "1.13+"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1)
        
        return None
    
    def scrape_with_selenium(self) -> List[VersionRecord]:
        """ä½¿ç”¨ Selenium çˆ¬å–"""
        if not self.setup_driver():
            return []
        
        try:
            print(f"ğŸŒ æ­£åœ¨è®¿é—®: {self.history_url}")
            self.driver.get(self.history_url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            print("âœ… é¡µé¢åŠ è½½å®Œæˆ")
            time.sleep(2)  # é¢å¤–ç­‰å¾…
            
            # è·å–é¡µé¢æºç 
            page_source = self.driver.page_source
            print(f"ğŸ“„ é¡µé¢å¤§å°: {len(page_source)} å­—ç¬¦")
            
            # ä¿å­˜é¡µé¢æºç ç”¨äºè°ƒè¯•
            with open("debug_page_source.html", "w", encoding="utf-8") as f:
                f.write(page_source)
            print("ğŸ’¾ å·²ä¿å­˜é¡µé¢æºç åˆ° debug_page_source.html")
            
            return self.parse_selenium_html(page_source)
            
        finally:
            if self.driver:
                self.driver.quit()
    
    def parse_selenium_html(self, html: str) -> List[VersionRecord]:
        """è§£æ Selenium è·å–çš„å†å²è®°å½•é¡µé¢ HTML"""
        records = []
        
        print("ğŸ” å¼€å§‹è§£æå†å²è®°å½•é¡µé¢...")
        
        print("ğŸ”„ ç›´æ¥è§£æ data-mw-revid å’ŒåŸºæœ¬ä¿¡æ¯...")
        
        # ç›´æ¥æŸ¥æ‰¾æ‰€æœ‰åŒ…å« oldid çš„è¡Œ
        oldid_lines = re.findall(r'<li[^>]*data-mw-revid="(\d+)"[^>]*>(.*?)</li>', html, re.DOTALL)
        
        print(f"ğŸ” æ‰¾åˆ° {len(oldid_lines)} ä¸ªä¿®è®¢è®°å½•")
        matches = []  # è®¾ç½®ä¸ºç©ºï¼Œå¼ºåˆ¶ä½¿ç”¨ä¸‹é¢çš„é€»è¾‘
        
        # å¤„ç†æ‰¾åˆ°çš„ä¿®è®¢è®°å½•
        for oldid, line_content in oldid_lines:
            # æå–æ—¶é—´æˆ³
            time_match = re.search(r'(\d{1,2}:\d{2}), (\d{1,2} \w+ \d{4})', line_content)
            if not time_match:
                continue
                
            time_part, date_part = time_match.groups()
            
            # æå–ç¼–è¾‘è€…
            editor_match = re.search(r'<a[^>]*title="User:([^"]*)"[^>]*><bdi>([^<]*)</bdi></a>', line_content)
            editor = editor_match.group(2) if editor_match else "Unknown"
            
            # æå–æ–‡ä»¶å¤§å°
            size_match = re.search(r'(\d{1,3}(?:,\d{3})*)\s+bytes', line_content)
            file_size = size_match.group(1) if size_match else "Unknown"
            
            # æå–å˜æ›´
            change_match = re.search(r'([+-]\d+)', line_content)
            change_bytes = change_match.group(1) if change_match else "0"
            
            # æå–æ³¨é‡Š
            comment_match = re.search(r'<span[^>]*class="comment[^"]*"[^>]*>([^<]*)</span>', line_content)
            comment = comment_match.group(1).strip() if comment_match else ""
            
            # æå–ç‰ˆæœ¬å·
            version = self.extract_version_from_text(comment) if comment else None
            
            # åªä¿ç•™æœ‰æ˜ç¡®ç‰ˆæœ¬å·çš„è®°å½•
            if version:
                wiki_url = f"{self.base_url}/w/Java_Edition_protocol/Entity_metadata?oldid={oldid}"
                
                record = VersionRecord(
                    version=version,
                    date=date_part,
                    time=time_part,
                    editor=editor,
                    file_size=file_size,
                    change_bytes=change_bytes,
                    description=comment,
                    wiki_url=wiki_url
                )
                records.append(record)
                print(f"âœ… å‘ç°ç‰ˆæœ¬: {version} ({date_part}) - oldid={oldid}")
            else:
                # è·³è¿‡æ²¡æœ‰ç‰ˆæœ¬å·çš„è®°å½•
                if comment:
                    print(f"â­ï¸  è·³è¿‡æ— ç‰ˆæœ¬: oldid={oldid} - {comment[:50]}...")
                else:
                    print(f"â­ï¸  è·³è¿‡æ— è¯„è®º: oldid={oldid}")
        
        print(f"ğŸ¯ è§£æå®Œæˆï¼Œæ‰¾åˆ° {len(records)} æ¡è®°å½•")
        return records





def save_results(records: List[VersionRecord]):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    if not records:
        return
    
    # JSON
    with open("minecraft_complete_versions.json", 'w', encoding='utf-8') as f:
        json.dump([asdict(r) for r in records], f, ensure_ascii=False, indent=2)
    
    
    print(f"ğŸ’¾ å·²ä¿å­˜: minecraft_complete_versions.json")


def parse_saved_page():
    """è§£æå·²ä¿å­˜çš„é¡µé¢å†…å®¹"""
    print("ğŸš€ è§£æå·²ä¿å­˜çš„é¡µé¢å†…å®¹")
    print("=" * 60)
    
    try:
        with open("debug_page_source.html", "r", encoding="utf-8") as f:
            html = f.read()
        
        print(f"ğŸ“„ è¯»å–é¡µé¢å†…å®¹: {len(html):,} å­—ç¬¦")
        
        scraper = SeleniumScraper()
        records = scraper.parse_selenium_html(html)
        
        if records:
            print(f"\nâœ… æˆåŠŸè§£æ {len(records)} ä¸ªç‰ˆæœ¬è®°å½•")
            
            # æ˜¾ç¤ºå‰10ä¸ªç‰ˆæœ¬
            print("\nğŸ“Š å‘ç°çš„ç‰ˆæœ¬:")
            for i, record in enumerate(records[:10]):
                version_str = record.version if record.version != "Unknown" else "?"
                print(f"  {i+1:2d}. {version_str:8} | {record.date:15} | {record.editor:12} | oldid={record.wiki_url.split('=')[-1]}")
            
            if len(records) > 10:
                print(f"  ... è¿˜æœ‰ {len(records) - 10} ä¸ªç‰ˆæœ¬")
            
            save_results(records)
            print(f"\nğŸ¯ å®Œæˆï¼å…±å¤„ç† {len(records)} ä¸ª Minecraft ç‰ˆæœ¬")
        else:
            print("âŒ æœªèƒ½è§£æä»»ä½•ç‰ˆæœ¬æ•°æ®")
            
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ° debug_page_source.html æ–‡ä»¶")
        print("è¯·å…ˆè¿è¡Œ Selenium çˆ¬è™«è·å–é¡µé¢å†…å®¹")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨ Minecraft ç‰ˆæœ¬å†å²çˆ¬è™«")
    print("=" * 60)
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä¿å­˜çš„é¡µé¢å†…å®¹
    import os
    if os.path.exists("debug_page_source.html"):
        print("ğŸ“„ å‘ç°å·²ä¿å­˜çš„é¡µé¢å†…å®¹ï¼Œç›´æ¥è§£æ...")
        parse_saved_page()
        return
    
    if not SELENIUM_AVAILABLE:
        print("âŒ Selenium æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install selenium")
        print("âŒ è¿˜éœ€è¦ä¸‹è½½ ChromeDriver: https://chromedriver.chromium.org/")
        return
    
    selenium_scraper = SeleniumScraper()
    records = selenium_scraper.scrape_with_selenium()
    
    if records:
        print(f"\nâœ… æˆåŠŸè·å– {len(records)} ä¸ªç‰ˆæœ¬è®°å½•")
        
        # æ˜¾ç¤ºå‰10ä¸ªç‰ˆæœ¬
        print("\nğŸ“Š å‘ç°çš„ç‰ˆæœ¬:")
        for i, record in enumerate(records[:10]):
            print(f"  {i+1:2d}. {record.version:8} | {record.date:15} | {record.editor}")
        
        if len(records) > 10:
            print(f"  ... è¿˜æœ‰ {len(records) - 10} ä¸ªç‰ˆæœ¬")
        
        save_results(records)
        print(f"\nğŸ¯ å®Œæˆï¼å…±å¤„ç† {len(records)} ä¸ª Minecraft ç‰ˆæœ¬")
    else:
        print("âŒ æœªèƒ½è·å–ä»»ä½•ç‰ˆæœ¬æ•°æ®")


if __name__ == "__main__":
    main()
